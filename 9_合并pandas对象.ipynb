{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并pandas对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataframe 添加新的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv('data/names.csv')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_list = ['Aria', 1]\n",
    "names.loc[4] = new_data_list\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.loc['five'] = ['Zach', 3]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.loc[len(names)] = {'Name':'Zayd', 'Age':2}\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.loc[len(names)] = pd.Series({'Age':32, 'Name':'Dean'})\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv('names.csv')\n",
    "names.append({'Name':'Aria', 'Age':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.append({'Name':'Aria', 'Age':1}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.index = ['Canada', 'Canada', 'USA', 'USA']\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.append({'Name':'Aria', 'Age':1}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series({'Name': 'Zach', 'Age': 3}, name=len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series({'Name': 'Zach', 'Age': 3}, name=len(names))\n",
    "s2 = pd.Series({'Name': 'Zayd', 'Age': 2}, name='USA')\n",
    "names.append([s1, s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_16 = pd.read_csv('baseball16.csv')\n",
    "bball_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = bball_16.iloc[0].to_dict()\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_dict = {k: '' if isinstance(v, str) else np.nan for k, v in data_dict.items()}\n",
    "print(new_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = []\n",
    "for i in range(1000):\n",
    "    d = dict()\n",
    "    for k, v in data_dict.items():\n",
    "        if isinstance(v, str):\n",
    "            d[k] = np.random.choice(list('abcde'))\n",
    "        else:\n",
    "            d[k] = np.random.randint(10)\n",
    "    random_data.append(pd.Series(d, name=i + len(bball_16)))\n",
    "\n",
    "random_data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "bball_16_copy = bball_16.copy()\n",
    "for row in random_data:\n",
    "    bball_16_copy = bball_16_copy.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "bball_16_copy = bball_16.copy()\n",
    "bball_16_copy = bball_16_copy.append(random_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连接多个dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_2016 = pd.read_csv('data/stocks_2016.csv', index_col='Symbol')\n",
    "stocks_2017 = pd.read_csv('data/stocks_2017.csv', index_col='Symbol')\n",
    "stocks_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_list = [stocks_2016, stocks_2017]\n",
    "pd.concat(s_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(s_list, keys=['2016', '2017'], names=['Year', 'Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(s_list, keys=['2016', '2017'], axis='columns', names=['Year', None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(s_list, join='inner', keys=['2016', '2017'], axis='columns', names=['Year', None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_2016.append(stocks_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_2015 = stocks_2016.copy()\n",
    "stocks_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat,join和merge的区别\n",
    "\n",
    "concat：\n",
    "- Pandas函数\n",
    "- 可以垂直和水平地连接两个或多个pandas对象\n",
    "- 只用索引对齐\n",
    "- 索引出现重复值时会报错\n",
    "- 默认是外连接（也可以设为内连接）\n",
    "\n",
    "join：\n",
    "- DataFrame方法\n",
    "- 只能水平连接两个或多个pandas对象\n",
    "- 对齐是靠被调用的DataFrame的列索引或行索引和另一个\n",
    "- 对象的行索引（不能是列索引\n",
    "- 通过笛卡尔积处理重复的索引值\n",
    "- 默认是左连接（也可以设为内连接、外连接和右连接）\n",
    "\n",
    "merge：\n",
    "- DataFrame方法\n",
    "- 只能水平连接两个DataFrame对象\n",
    "- 对齐是靠被调用的DataFrame的列或行索引和另一个\n",
    "- DataFrame的列或行索引\n",
    "- 通过笛卡尔积处理重复的索引值\n",
    "- 默认是内连接（也可以设为左连接、外连接、右连接）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "years = 2016, 2017, 2018\n",
    "stock_tables = [pd.read_csv('data/stocks_{}.csv'.format(year), index_col='Symbol') for year in years]\n",
    "\n",
    "def display_frames(frames, num_spaces=0):\n",
    "    t_style = '<table style=\"display:inline;\"'\n",
    "    tables_html = [df.to_html().replace('<table', t_style) for df in frames]\n",
    "    space = '&nbsp;' * num_spaces\n",
    "    display_html(space.join(tables_html), raw=True)\n",
    "\n",
    "display_frames(stock_tables, 30)\n",
    "stocks_2016, stocks_2017, stocks_2018 = stock_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(stock_tables, keys=[2016, 2017, 2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dict(zip(years,stock_tables)), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_2016.join(stocks_2017, lsuffix='_2016', rsuffix='_2017', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = [stocks_2017.add_suffix('_2017'), stocks_2018.add_suffix('_2018')]\n",
    " \n",
    "stocks_2016.add_suffix('_2016').join(other, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_join = stocks_2016.add_suffix('_2016').join(other, how='outer')\n",
    "stock_concat = pd.concat(dict(zip(years,stock_tables)), axis='columns')\n",
    "\n",
    "stock_concat.columns = stock_concat.columns.get_level_values(1) + '_' + \\\n",
    "                       stock_concat.columns.get_level_values(0).astype(str)\n",
    "\n",
    "stock_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = stocks_2016.merge(stocks_2017, left_index=True, right_index=True, how='outer', suffixes=('_2016', '_2017'))\n",
    "stock_merge = step1.merge(stocks_2018.add_suffix('_2018'), left_index=True, right_index=True, how='outer')\n",
    "stock_concat.equals(stock_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['prices', 'transactions']\n",
    "food_tables = [pd.read_csv('data/food_{}.csv'.format(name)) for name in names]\n",
    "food_prices, food_transactions = food_tables\n",
    "display_frames(food_tables, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_transactions.merge(food_prices, on=['item', 'store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_transactions.merge(food_prices.query('Date== 2017'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_prices_join = food_prices.query('Date ==2017').set_index(['item', 'store'])\n",
    "food_prices_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_transactions.join(food_prices_join, on=['item', 'store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([food_transactions.set_index(['item', 'store']), food_prices.set_index(['item', 'store'])], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "df_list = []\n",
    "for filename in glob.glob('data/gasprices/*.csv'):\n",
    "    df_list.append(pd.read_csv(filename, index_col='Week', parse_dates=['Week']))\n",
    "\n",
    "gas = pd.concat(df_list, axis='columns')\n",
    "gas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连接 sql 数据库"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
